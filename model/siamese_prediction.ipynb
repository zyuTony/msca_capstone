{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "FjMhb-vHTUHg",
   "metadata": {
    "id": "FjMhb-vHTUHg"
   },
   "source": [
    "\n",
    "\n",
    "### Import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fc1ae7",
   "metadata": {
    "id": "63fc1ae7"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary Library \n",
    "import torchvision\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0adc683",
   "metadata": {
    "id": "b0adc683"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d011e8d",
   "metadata": {
    "id": "3d011e8d"
   },
   "source": [
    "### Functions and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9040600",
   "metadata": {
    "id": "b9040600"
   },
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0daa20e8",
   "metadata": {
    "id": "0daa20e8"
   },
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset():\n",
    "    \n",
    "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.training_df=pd.read_csv(training_csv)\n",
    "        self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
    "        self.training_dir = training_dir    \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        # getting the image path\n",
    "        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n",
    "        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n",
    "        \n",
    "        \n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdf5044",
   "metadata": {
    "id": "6bdf5044"
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Setting up the Sequential of CNN Layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Defining the fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(30976, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(128,2))\n",
    "        \n",
    "  \n",
    "  \n",
    "    def forward_once(self, x):\n",
    "        # Forward pass \n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # forward pass of input 1\n",
    "        output1 = self.forward_once(input1)\n",
    "        # forward pass of input 2\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aeffdc7",
   "metadata": {
    "id": "1aeffdc7"
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J28-qYV18d0z",
   "metadata": {
    "id": "J28-qYV18d0z"
   },
   "source": [
    "### Evaluate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc0a2a0",
   "metadata": {
    "id": "t5tFOxzneX4E"
   },
   "outputs": [],
   "source": [
    "def siamese_eval_dataload(test_image, datafolder):\n",
    "    prediction_df = []\n",
    "    for label in os.listdir(datafolder):\n",
    "        for image in os.listdir(datafolder + label):\n",
    "            prediction_df.append({\n",
    "              'test_img':test_image,\n",
    "              'img2': datafolder + label + \"/\" + image,\n",
    "              'labels': label,   \n",
    "            })\n",
    "\n",
    "    prediction_df = pd.DataFrame(prediction_df)\n",
    "    prediction_df.to_csv(\"../data/prediction.csv\", index=False)\n",
    "\n",
    "    # load prediction csv\n",
    "    prediction_csv = \"../data/prediction.csv\"\n",
    "\n",
    "    prediction_dataset = SiameseNetworkDataset(training_csv=prediction_csv,training_dir=\"\",\n",
    "                                          transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                                        transforms.ToTensor()\n",
    "                                                                        ]))\n",
    "\n",
    "    prediction_dataloader = DataLoader(prediction_dataset, batch_size=1)\n",
    "\n",
    "    return prediction_df, prediction_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "t5tFOxzneX4E",
   "metadata": {
    "id": "t5tFOxzneX4E"
   },
   "outputs": [],
   "source": [
    "def siamese_eval(test_image, datafolder, net, n=3):\n",
    "    prediction_df, prediction_dataloader = siamese_eval_dataload(test_image, datafolder)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dissimilarity = []\n",
    "\n",
    "    # Get dissimilarity for every combination of test img and our imgs\n",
    "    for i, data in enumerate(prediction_dataloader,0): \n",
    "        test, compare, label = data\n",
    "        concatenated = torch.cat((test, compare),0)\n",
    "        output1, output2 = net(test.to(device), compare.to(device))\n",
    "        eucledian_distance = F.pairwise_distance(output1, output2)\n",
    "        dissimilarity.append(eucledian_distance.item()*100)\n",
    "\n",
    "    dissim_df = pd.DataFrame({\"score\":dissimilarity,\n",
    "                            \"labels\":prediction_df['labels']})\n",
    "  \n",
    "    # Get avg dissimilarity score for each label\n",
    "    labels = []\n",
    "    scores = []\n",
    "    rmsquares = []\n",
    "    for label in set(prediction_df['labels']):\n",
    "        scores_for_label = dissim_df[dissim_df['labels']==label]['score'].tolist()\n",
    "        labels.append(label)\n",
    "        scores.append(sum(scores_for_label)/len(scores_for_label))\n",
    "        rmsquare = np.sqrt(np.mean(np.square(scores_for_label)))\n",
    "        rmsquares.append(rmsquare)\n",
    "\n",
    "    # Get labels and the corresponding avg score\n",
    "    avg_score_df = pd.DataFrame({\"labels\":labels,\n",
    "                              \"score\":scores,\n",
    "                              \"root_mean_squared\":rmsquares})\n",
    "    \n",
    "    top_n_pred = avg_score_df.sort_values(\"score\", ascending=True)['labels'].head(n).tolist()\n",
    "   \n",
    "    return top_n_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W5yUQhSoiSJR",
   "metadata": {
    "id": "W5yUQhSoiSJR"
   },
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13df39e",
   "metadata": {
    "id": "kjQXYhXs-xHQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zongy\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6', '1', '4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"./model_final.pt\"\n",
    "net = SiameseNetwork() \n",
    "net.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
    "net.eval()\n",
    "datafolder = \"../data/manual-clusters/20220430/categorized_new/\"\n",
    "test_image = \"../data/manual-clusters/20220430/categorized_new/1/gleeful-kangaroomouse-0.jpg\"\n",
    "results = siamese_eval(test_image, datafolder, net, n=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "kjQXYhXs-xHQ",
   "metadata": {
    "id": "kjQXYhXs-xHQ"
   },
   "outputs": [],
   "source": [
    "testimgs = []\n",
    "for label in os.listdir(datafolder):\n",
    "    for image in os.listdir(datafolder + label):\n",
    "        testimgs.append({\n",
    "            'dir': datafolder + label + \"/\" + image,\n",
    "            'true_label': label,   \n",
    "        })\n",
    "testimgs = pd.DataFrame(testimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicated and true label\n",
    "pred = []\n",
    "true = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i, row in tqdm(testimgs.iterrows()):\n",
    "    test_image = row['dir']\n",
    "    pred.append(siamese_eval(test_image, datafolder, net, n=3))\n",
    "    true.append(row['true_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images with each labels\n",
    "top_3_pred = pd.DataFrame({'pred':pred,\n",
    "              'true':true})\n",
    "\n",
    "top_3_pred['true'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 accuracy for each label\n",
    "correct = []\n",
    "for i, row in top_3_pred.iterrows():\n",
    "    if row['true'] in row['pred']:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)\n",
    "top_3_pred['correct'] = correct\n",
    "print(top_3_pred.groupby(['true'])['correct'].mean())\n",
    "\n",
    "# Top 1 accuracy for overall\n",
    "top_3_pred['correct'].mean()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
